"""
Emotion Recognition - Vision-Frame-Based Face Channel

__author__ = "Pablo Barros"

__version__ = "0.1"
__maintainer__ = "Pablo Barros"
__email__ = "barros@informatik.uni-hamburg.de"

More information about the implementation of the model:

Barros, P., Churamani, N., & Sciutti, A. (2020). The FaceChannel: A Light-weight Deep Neural Network for Facial Expression Recognition. arXiv preprint arXiv:2004.08195.

Barros, P., & Wermter, S. (2016). Developing crossmodal expression recognition based on a deep neural model. Adaptive behavior, 24(5), 373-396.
http://journals.sagepub.com/doi/full/10.1177/1059712316664017

"""



from FaceChannel.FaceChannel import FaceChannel

faceChannelCat = FaceChannel("Cat", loadModel=True)
faceChannelDim = FaceChannel("Dim", loadModel=True)
#
# import cv2
# from Utils import imageProcessingUtil, modelDictionary, modelLoader, GUIController
# import numpy
#
#
# """Information about the created image"""
# finalImageSize = (1024,768) # Size of the final image generated by the demo
# categoricalInitialPosition = 460 # Initial position for adding the categorical graph in the final image
# faceSize = (64,64) # Input size for both models: categorical and dimensional
# faceDetectionMaximumFrequency = 20 # Frequency that a face will be detected: every X frames.
#
# GUIController = GUIController.GUIController()
#
# cap = cv2.VideoCapture(0)
#
# arousals = []
# valences = []
#
#
# cap.open(0)
#
# if cap.isOpened():  # try to get the first frame
#     rval, f = cap.read()
# else:
#     rval = False
#
#
# # video = "/home/pablo/Documents/Datasets/wristbot/videos/S002_G1_bl.mp4"
# #
# # cap = cv2.VideoCapture(video) #open the video
#
# frames = 0
# while(True):
#     # Capture frame-by-frame
#
#         rval, frame = cap.read()
#
#         # frame = cv2.resize(frame,(640,480))
#
#         # detect faces
#         facePoints, face = imageProcessing.detectFace(frame)
#
#         # create display image and copy the captured frame to it
#         image = numpy.zeros((finalImageSize[1], finalImageSize[0], 3), numpy.uint8)
#         image[0:480, 0:640] = frame
#         frame = image
#
#          # If a face is detected
#         if not len(face) == 0:
#             # pre-process the face
#             face = imageProcessing.preProcess(face, faceSize)
#
#             # Obtain dimensional classification
#             dimensionalRecognition = numpy.array(modelDimensional.classify(face))
#
#             #Obtain Categorical classification
#             categoricalRecognition = modelCategorical.classify(face)[0]
#
#             # Print the square around the categorical face
#             frame = GUIController.createDetectedFacGUI(frame,facePoints,modelDictionary=modelCategorical.modelDictionary, categoricalClassificationReport=categoricalRecognition)
#
#             # # # Create the categorical classification
#             frame = GUIController.createCategoricalEmotionGUI(categoricalRecognition, frame,
#                                                               modelCategorical.modelDictionary,
#                                                               initialPosition=categoricalInitialPosition)
#             # Create the dimensional graph
#             frame = GUIController.createDimensionalEmotionGUI(dimensionalRecognition, frame, categoricalReport=[], categoricalDictionary=None)
#
#             if len(arousals) > 100:
#                 arousals.pop(0)
#                 valences.pop(0)
#
#             #Create dimensional plot
#             arousals.append(dimensionalRecognition[0][0][0])
#             valences.append(dimensionalRecognition[1][0][0])
#
#             frame = GUIController.createDimensionalPlotGUI(arousals, valences, frame)
#
#
#         #Display the resulting frame
#         cv2.imshow('frame',frame)
#
#         # frames = frames+1
#         # cv2.imwrite("/home/pablo/Documents/Datasets/wristbot/frames/"+str(frames)+".png", frame)
#         if cv2.waitKey(1) & 0xFF == ord('q'):
#             break
#
# # When everything done, release the capture
# cap.release()
# cv2.destroyAllWindows()